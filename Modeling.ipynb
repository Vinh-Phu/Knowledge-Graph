{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvahtkVcPI7B",
        "outputId": "17a8d656-43ad-4317-e357-e389f18a7cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-01 14:46:09--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.12.128, 172.217.194.128, 142.250.4.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.12.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M  22.8MB/s    in 30s     \n",
            "\n",
            "2023-07-01 14:46:40 (21.3 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
            "\n",
            "Archive:  multi_cased_L-12_H-768_A-12.zip\n",
            "   creating: multi_cased_L-12_H-768_A-12/\n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Download VnCoreNLP-1.1.1.jar & all of its  component (i.e. RDRSegmenter, pos, ner, deprel)\n",
        "# !mkdir -p vncorenlp/models/wordsegmenter\n",
        "# !mkdir -p vncorenlp/models/dep\n",
        "# !mkdir -p vncorenlp/models/ner\n",
        "# !mkdir -p vncorenlp/models/postagger\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "!unzip multi_cased_L-12_H-768_A-12.zip\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/dep/vi-dep.xz\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-500brownclusters.xz\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-ner.xz\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/ner/vi-pretrainedembeddings.xz\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/postagger/vi-tagger\n",
        "\n",
        "\n",
        "# !mv VnCoreNLP-1.1.1.jar vncorenlp/\n",
        "\n",
        "# !mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "# !mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n",
        "\n",
        "# !mv vi-dep.xz vncorenlp/models/dep/\n",
        "\n",
        "# !mv vi-500brownclusters.xz vncorenlp/models/ner/\n",
        "# !mv vi-ner.xz vncorenlp/models/ner/\n",
        "# !mv vi-pretrainedembeddings.xz vncorenlp/models/ner/\n",
        "!pip -q install pandarallel\n",
        "# !mv vi-tagger vncorenlp/models/postagger/\n",
        "!pip -q install vncorenlp pyvi transformers underthesea sentence_transformers keybert\n",
        "!pip -q install keybert[flair]\n",
        "!pip -q install keybert[gensim]\n",
        "!pip -q install keybert[spacy]\n",
        "!pip -q install keybert[use]\n",
        "!pip -q install keras_bert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow==2.11.0\n",
        "!pip install tensorflow_probability==0.12.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A-oMcUl7R64T",
        "outputId": "0bc39ff5-889f-4ebf-fc0d-e3be76070f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (16.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (4.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorboard-plugin-wit, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-text 2.12.1 requires tensorflow<2.13,>=2.12.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_probability==0.12.2\n",
            "  Downloading tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/4.8 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m4.1/4.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (1.22.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability==0.12.2) (0.1.8)\n",
            "Installing collected packages: tensorflow_probability\n",
            "  Attempting uninstall: tensorflow_probability\n",
            "    Found existing installation: tensorflow-probability 0.20.1\n",
            "    Uninstalling tensorflow-probability-0.20.1:\n",
            "      Successfully uninstalled tensorflow-probability-0.20.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires tensorflow-probability>=0.13.0, but you have tensorflow-probability 0.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow_probability-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbLXSTkm5poV"
      },
      "source": [
        "#Restart Kernel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SY47wdfbR-sa",
        "outputId": "5cc0a6dc-85d5-4e88-cb61-e4250cb75b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEtlD5bMYa33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c515ba2d-79d0-4fbd-9408-79486338ebe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO: Pandarallel will run on 1 workers.\n",
            "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "tqdm.pandas()\n",
        "import json\n",
        "import re\n",
        "from transformers import pipeline\n",
        "import transformers\n",
        "import sklearn\n",
        "import os\n",
        "from glob import glob\n",
        "from pprint import pprint\n",
        "import nltk\n",
        "import math\n",
        "import torch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from random import choice\n",
        "import keras.backend as K\n",
        "from keras_bert import Tokenizer\n",
        "import codecs\n",
        "import unicodedata\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "from datetime import datetime\n",
        "from pyvi import ViTokenizer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "from transformers import default_data_collator\n",
        "from scipy import sparse\n",
        "import underthesea\n",
        "from underthesea import word_tokenize\n",
        "from underthesea import text_normalize\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8r4wNlHKkpe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "BERT_MAX_LEN = 512\n",
        "RANDOM_SEED = 2023\n",
        "\n",
        "def find_head_idx(source, target):\n",
        "    target_len = len(target)\n",
        "    for i in range(len(source)):\n",
        "        if source[i: i + target_len] == target:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "def to_tuple(sent):\n",
        "    triple_list = []\n",
        "    for triple in sent['triple_gold']:\n",
        "        triple_list.append(tuple(triple))\n",
        "    sent['triple_gold'] = triple_list\n",
        "\n",
        "def seq_padding(batch, padding=0):\n",
        "    length_batch = [len(seq) for seq in batch]\n",
        "    max_length = max(length_batch)\n",
        "    return np.array([\n",
        "        np.concatenate([seq, [padding] * (max_length - len(seq))]) if len(seq) < max_length else seq for seq in batch\n",
        "    ])\n",
        "\n",
        "def load_data(train_path, dev_path,test_path, rel_dict_path):\n",
        "    train_data = json.load(open(train_path))\n",
        "    dev_data = json.load(open(dev_path))\n",
        "    test_data = json.load(open(test_path))\n",
        "    rel2id = json.load(open(rel_dict_path))\n",
        "\n",
        "    num_rels = len(rel2id)\n",
        "\n",
        "    random_order = list(range(len(train_data)))\n",
        "    np.random.seed(RANDOM_SEED)\n",
        "    np.random.shuffle(random_order)\n",
        "    train_data = [train_data[i] for i in random_order]\n",
        "\n",
        "    for sent in train_data:\n",
        "        to_tuple(sent)\n",
        "    for sent in dev_data:\n",
        "        to_tuple(sent)\n",
        "    for sent in test_data:\n",
        "        to_tuple(sent)\n",
        "\n",
        "    print(\"train_data len:\", len(train_data))\n",
        "    print(\"test_data len:\",len(test_data))\n",
        "    print(\"dev_data len:\", len(dev_data))\n",
        "\n",
        "    return train_data, dev_data,test_data, rel2id, num_rels\n",
        "\n",
        "\n",
        "class data_generator:\n",
        "    def __init__(self, data, tokenizer, rel2id, num_rels, maxlen, batch_size=32):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.maxlen = maxlen\n",
        "        self.rel2id = rel2id\n",
        "        self.num_rels = num_rels\n",
        "        self.steps = len(self.data) // self.batch_size\n",
        "        if len(self.data) % self.batch_size != 0:\n",
        "            self.steps += 1\n",
        "    def __len__(self):\n",
        "        return self.steps\n",
        "    def __iter__(self):\n",
        "        while True:\n",
        "            idxs = list(range(len(self.data)))\n",
        "            np.random.seed(RANDOM_SEED)\n",
        "            np.random.shuffle(idxs)\n",
        "            tokens_batch, segments_batch, sub_heads_batch, sub_tails_batch, sub_head_batch, sub_tail_batch, obj_heads_batch, obj_tails_batch = [], [], [], [], [], [], [], []\n",
        "            for idx in idxs:\n",
        "                line = self.data[idx]\n",
        "                text = ' '.join(line['text'].split()[:self.maxlen])\n",
        "                tokens = self.tokenizer.tokenize(text)\n",
        "                if len(tokens) > BERT_MAX_LEN:\n",
        "                    tokens = tokens[:BERT_MAX_LEN]\n",
        "                text_len = len(tokens)\n",
        "\n",
        "                s2ro_map = {}\n",
        "                for triple in line['triple_gold']:\n",
        "                    triple = (self.tokenizer.tokenize(triple[0])[1:-1], triple[1], self.tokenizer.tokenize(triple[2])[1:-1])\n",
        "                    sub_head_idx = find_head_idx(tokens, triple[0])\n",
        "                    obj_head_idx = find_head_idx(tokens, triple[2])\n",
        "                    if sub_head_idx != -1 and obj_head_idx != -1:\n",
        "                        sub = (sub_head_idx, sub_head_idx + len(triple[0]) - 1)\n",
        "                        if sub not in s2ro_map:\n",
        "                            s2ro_map[sub] = []\n",
        "                        s2ro_map[sub].append((obj_head_idx,\n",
        "                                           obj_head_idx + len(triple[2]) - 1,\n",
        "                                           self.rel2id[triple[1]]))\n",
        "\n",
        "                if s2ro_map:\n",
        "                    token_ids, segment_ids = self.tokenizer.encode(first=text)\n",
        "                    if len(token_ids) > text_len:\n",
        "                        token_ids = token_ids[:text_len]\n",
        "                        segment_ids = segment_ids[:text_len]\n",
        "                    tokens_batch.append(token_ids)\n",
        "                    segments_batch.append(segment_ids)\n",
        "                    sub_heads, sub_tails = np.zeros(text_len), np.zeros(text_len)\n",
        "                    for s in s2ro_map:\n",
        "                        sub_heads[s[0]] = 1\n",
        "                        sub_tails[s[1]] = 1\n",
        "                    sub_head, sub_tail = choice(list(s2ro_map.keys()))\n",
        "                    obj_heads, obj_tails = np.zeros((text_len, self.num_rels)), np.zeros((text_len, self.num_rels))\n",
        "                    for ro in s2ro_map.get((sub_head, sub_tail), []):\n",
        "                        obj_heads[ro[0]][ro[2]] = 1\n",
        "                        obj_tails[ro[1]][ro[2]] = 1\n",
        "                    sub_heads_batch.append(sub_heads)\n",
        "                    sub_tails_batch.append(sub_tails)\n",
        "                    sub_head_batch.append([sub_head])\n",
        "                    sub_tail_batch.append([sub_tail])\n",
        "                    obj_heads_batch.append(obj_heads)\n",
        "                    obj_tails_batch.append(obj_tails)\n",
        "                    if len(tokens_batch) == self.batch_size or idx == idxs[-1]:\n",
        "                        tokens_batch = seq_padding(tokens_batch)\n",
        "                        segments_batch = seq_padding(segments_batch)\n",
        "                        sub_heads_batch = seq_padding(sub_heads_batch)\n",
        "                        sub_tails_batch = seq_padding(sub_tails_batch)\n",
        "                        obj_heads_batch = seq_padding(obj_heads_batch, np.zeros(self.num_rels))\n",
        "                        obj_tails_batch = seq_padding(obj_tails_batch, np.zeros(self.num_rels))\n",
        "                        sub_head_batch, sub_tail_batch = np.array(sub_head_batch), np.array(sub_tail_batch)\n",
        "                        yield [tokens_batch, segments_batch, sub_heads_batch, sub_tails_batch, sub_head_batch, sub_tail_batch, obj_heads_batch, obj_tails_batch], None\n",
        "                        tokens_batch, segments_batch, sub_heads_batch, sub_tails_batch, sub_head_batch, sub_tail_batch, obj_heads_batch, obj_tails_batch, = [], [], [], [], [], [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxstDNbSYa3C"
      },
      "outputs": [],
      "source": [
        "\n",
        "BERT_MAX_LEN = 512\n",
        "\n",
        "class HBTokenizer(Tokenizer):\n",
        "    def _tokenize(self, text):\n",
        "        if not self._cased:\n",
        "            text = unicodedata.normalize('NFD', text)\n",
        "            text = ''.join([ch for ch in text if unicodedata.category(ch) != 'Mn'])\n",
        "            text = text.lower()\n",
        "        spaced = ''\n",
        "        for ch in text:\n",
        "            if ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\n",
        "                continue\n",
        "            else:\n",
        "                spaced += ch\n",
        "        tokens = []\n",
        "        for word in spaced.strip().split():\n",
        "            tokens += self._word_piece_tokenize(word)\n",
        "            tokens.append('[unused1]')\n",
        "        return tokens\n",
        "\n",
        "def get_tokenizer(vocab_path):\n",
        "    token_dict = {}\n",
        "    with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "        for line in reader:\n",
        "            token = line.strip()\n",
        "            token_dict[token] = len(token_dict)\n",
        "    return HBTokenizer(token_dict, cased=True)\n",
        "\n",
        "def seq_gather(x):\n",
        "    seq, idxs = x\n",
        "    idxs = K.cast(idxs, 'int32')\n",
        "    batch_idxs = K.arange(0, K.shape(seq)[0])\n",
        "    batch_idxs = K.expand_dims(batch_idxs, 1)\n",
        "    idxs = K.concatenate([batch_idxs, idxs], 1)\n",
        "    return K.tf.gather_nd(seq, idxs)\n",
        "\n",
        "def extract_items(subject_model, object_model, tokenizer, text_in, id2rel, h_bar=0.5, t_bar=0.5):\n",
        "    tokens = tokenizer.tokenize(text_in)\n",
        "    token_ids, segment_ids = tokenizer.encode(first=text_in)\n",
        "    token_ids, segment_ids = np.array([token_ids]), np.array([segment_ids])\n",
        "    if len(token_ids[0]) > BERT_MAX_LEN:\n",
        "        token_ids = token_ids[:,:BERT_MAX_LEN]\n",
        "        segment_ids = segment_ids[:,:BERT_MAX_LEN]\n",
        "    sub_heads_logits, sub_tails_logits = subject_model.predict([token_ids, segment_ids],verbose=None)\n",
        "    sub_heads, sub_tails = np.where(sub_heads_logits[0] > h_bar)[0], np.where(sub_tails_logits[0] > t_bar)[0]\n",
        "    subjects = []\n",
        "    for sub_head in sub_heads:\n",
        "        sub_tail = sub_tails[sub_tails >= sub_head]\n",
        "        if len(sub_tail) > 0:\n",
        "            sub_tail = sub_tail[0]\n",
        "            subject = tokens[sub_head: sub_tail]\n",
        "            subjects.append((subject, sub_head, sub_tail))\n",
        "    if subjects:\n",
        "        triple_list = []\n",
        "        token_ids = np.repeat(token_ids, len(subjects), 0)\n",
        "        segment_ids = np.repeat(segment_ids, len(subjects), 0)\n",
        "        sub_heads, sub_tails = np.array([sub[1:] for sub in subjects]).T.reshape((2, -1, 1))\n",
        "        obj_heads_logits, obj_tails_logits = object_model.predict([token_ids, segment_ids, sub_heads, sub_tails],verbose=None)\n",
        "        for i, subject in enumerate(subjects):\n",
        "            sub = subject[0]\n",
        "            sub = ''.join([i.lstrip(\"##\") for i in sub])\n",
        "            sub = ' '.join(sub.split('[unused1]'))\n",
        "            obj_heads, obj_tails = np.where(obj_heads_logits[i] > h_bar), np.where(obj_tails_logits[i] > t_bar)\n",
        "            for obj_head, rel_head in zip(*obj_heads):\n",
        "                for obj_tail, rel_tail in zip(*obj_tails):\n",
        "                    if obj_head <= obj_tail and rel_head == rel_tail:\n",
        "                        rel = id2rel[rel_head]\n",
        "                        obj = tokens[obj_head: obj_tail]\n",
        "                        obj = ''.join([i.lstrip(\"##\") for i in obj])\n",
        "                        obj = ' '.join(obj.split('[unused1]'))\n",
        "                        triple_list.append((sub, rel, obj))\n",
        "                        break\n",
        "        triple_set = set()\n",
        "        for s, r, o in triple_list:\n",
        "            triple_set.add((s, r, o))\n",
        "        return list(triple_set)\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "def partial_match(pred_set, gold_set):\n",
        "    pred = {(i[0].split(' ')[0] if len(i[0].split(' ')) > 0 else i[0], i[1], i[2].split(' ')[0] if len(i[2].split(' ')) > 0 else i[2]) for i in pred_set}\n",
        "    gold = {(i[0].split(' ')[0] if len(i[0].split(' ')) > 0 else i[0], i[1], i[2].split(' ')[0] if len(i[2].split(' ')) > 0 else i[2]) for i in gold_set}\n",
        "    return pred, gold\n",
        "\n",
        "def metric(subject_model, object_model, eval_data, id2rel, tokenizer, exact_match=False, output_path=None):\n",
        "    if output_path:\n",
        "        F = open(output_path, 'w')\n",
        "    orders = ['subject', 'relation', 'object']\n",
        "    correct_num, predict_num, gold_num = 1e-10, 1e-10, 1e-10\n",
        "    for line in tqdm(iter(eval_data)):\n",
        "        Pred_triples = set(extract_items(subject_model, object_model, tokenizer, line['text'], id2rel))\n",
        "        Gold_triples = set(line['triple_gold'])\n",
        "        print(Pred_triples)\n",
        "        Pred_triples_eval, Gold_triples_eval = partial_match(Pred_triples, Gold_triples) if not exact_match else (Pred_triples, Gold_triples)\n",
        "\n",
        "        correct_num += len(Pred_triples_eval & Gold_triples_eval)\n",
        "        predict_num += len(Pred_triples_eval)\n",
        "        gold_num += len(Gold_triples_eval)\n",
        "\n",
        "        if output_path:\n",
        "            result = json.dumps({\n",
        "                'text': line['text'],\n",
        "                'triple_list_gold': [\n",
        "                    dict(zip(orders, triple)) for triple in Gold_triples\n",
        "                ],\n",
        "                'triple_list_pred': [\n",
        "                    dict(zip(orders, triple)) for triple in Pred_triples\n",
        "                ],\n",
        "                'new': [\n",
        "                    dict(zip(orders, triple)) for triple in Pred_triples - Gold_triples\n",
        "                ],\n",
        "                'lack': [\n",
        "                    dict(zip(orders, triple)) for triple in Gold_triples - Pred_triples\n",
        "                ]\n",
        "            }, ensure_ascii=False, indent=4)\n",
        "            F.write(result + '\\n')\n",
        "    if output_path:\n",
        "        F.close()\n",
        "\n",
        "    precision = correct_num / predict_num\n",
        "    recall = correct_num / gold_num\n",
        "    f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    print(f'correct_num:{correct_num}\\npredict_num:{predict_num}\\ngold_num:{gold_num}')\n",
        "    return precision, recall, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZVhW4xyXb2B"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def E2EModel(bert_config_path, bert_checkpoint_path, LR, num_rels):\n",
        "    bert_model = load_trained_model_from_checkpoint(bert_config_path, bert_checkpoint_path, seq_len=None)\n",
        "    print(bert_model)\n",
        "    for l in bert_model.layers:\n",
        "        l.trainable = True\n",
        "\n",
        "    tokens_in = Input(shape=(None,))\n",
        "    segments_in = Input(shape=(None,))\n",
        "    gold_sub_heads_in = Input(shape=(None,))\n",
        "    gold_sub_tails_in = Input(shape=(None,))\n",
        "    sub_head_in = Input(shape=(1,))\n",
        "    sub_tail_in = Input(shape=(1,))\n",
        "    gold_obj_heads_in = Input(shape=(None, num_rels))\n",
        "    gold_obj_tails_in = Input(shape=(None, num_rels))\n",
        "\n",
        "    tokens, segments, gold_sub_heads, gold_sub_tails, sub_head, sub_tail, gold_obj_heads, gold_obj_tails = tokens_in, segments_in, gold_sub_heads_in, gold_sub_tails_in, sub_head_in, sub_tail_in, gold_obj_heads_in, gold_obj_tails_in\n",
        "    mask = Lambda(lambda x: K.cast(K.greater(K.expand_dims(x, 2), 0), 'float32'))(tokens)\n",
        "\n",
        "    tokens_feature = bert_model([tokens, segments])\n",
        "    pred_sub_heads = Dense(1, activation='sigmoid')(tokens_feature)\n",
        "    pred_sub_tails = Dense(1, activation='sigmoid')(tokens_feature)\n",
        "\n",
        "    subject_model = Model([tokens_in, segments_in], [pred_sub_heads, pred_sub_tails])\n",
        "\n",
        "\n",
        "    sub_head_feature = Lambda(seq_gather)([tokens_feature, sub_head])\n",
        "    sub_tail_feature = Lambda(seq_gather)([tokens_feature, sub_tail])\n",
        "    sub_feature = Average()([sub_head_feature, sub_tail_feature])\n",
        "\n",
        "    tokens_feature = Add()([tokens_feature, sub_feature])\n",
        "    pred_obj_heads = Dense(num_rels, activation='sigmoid')(tokens_feature)\n",
        "    pred_obj_tails = Dense(num_rels, activation='sigmoid')(tokens_feature)\n",
        "\n",
        "    object_model = Model([tokens_in, segments_in, sub_head_in, sub_tail_in], [pred_obj_heads, pred_obj_tails])\n",
        "\n",
        "\n",
        "    hbt_model = Model([tokens_in, segments_in, gold_sub_heads_in, gold_sub_tails_in, sub_head_in, sub_tail_in, gold_obj_heads_in, gold_obj_tails_in],\n",
        "                        [pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails])\n",
        "\n",
        "    gold_sub_heads = K.expand_dims(gold_sub_heads, 2)\n",
        "    gold_sub_tails = K.expand_dims(gold_sub_tails, 2)\n",
        "\n",
        "    sub_heads_loss = K.binary_crossentropy(gold_sub_heads, pred_sub_heads)\n",
        "    sub_heads_loss = K.sum(sub_heads_loss * mask) / K.sum(mask)\n",
        "    sub_tails_loss = K.binary_crossentropy(gold_sub_tails, pred_sub_tails)\n",
        "    sub_tails_loss = K.sum(sub_tails_loss * mask) / K.sum(mask)\n",
        "\n",
        "    obj_heads_loss = K.sum(K.binary_crossentropy(gold_obj_heads, pred_obj_heads), 2, keepdims=True)\n",
        "    obj_heads_loss = K.sum(obj_heads_loss * mask) / K.sum(mask)\n",
        "    obj_tails_loss = K.sum(K.binary_crossentropy(gold_obj_tails, pred_obj_tails), 2, keepdims=True)\n",
        "    obj_tails_loss = K.sum(obj_tails_loss * mask) / K.sum(mask)\n",
        "\n",
        "    loss = (sub_heads_loss + sub_tails_loss) + (obj_heads_loss + obj_tails_loss)\n",
        "\n",
        "    hbt_model.add_loss(loss)\n",
        "    hbt_model.compile(optimizer=Adam(LR))\n",
        "    hbt_model.summary()\n",
        "\n",
        "    return subject_model, object_model, hbt_model\n",
        "\n",
        "class Evaluate(Callback):\n",
        "    def __init__(self, subject_model, object_model, tokenizer, id2rel, eval_data, save_weights_path, min_delta=1e-4, patience=7):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.monitor_op = np.greater\n",
        "        self.subject_model = subject_model\n",
        "        self.object_model = object_model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.id2rel = id2rel\n",
        "        self.eval_data = eval_data\n",
        "        self.save_weights_path = save_weights_path\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.step = 0\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.warmup_epochs = 2\n",
        "        self.best = -np.Inf\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        precision, recall, f1 = metric(self.subject_model, self.object_model, self.eval_data, self.id2rel, self.tokenizer)\n",
        "        if self.monitor_op(f1 - self.min_delta, self.best) or self.monitor_op(self.min_delta, f1):\n",
        "            self.best = f1\n",
        "            self.wait = 0\n",
        "            self.model.save_weights(self.save_weights_path)\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "        print('f1: %.4f, precision: %.4f, recall: %.4f, best f1: %.4f\\n' % (f1, precision, recall, self.best))\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training relation model"
      ],
      "metadata": {
        "id": "U0UWT3AAvwDv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myqib3GwXVuR"
      },
      "outputs": [],
      "source": [
        "# bert_model = 'multi_cased_L-12_H-768_A-12'\n",
        "# bert_config_path =  bert_model + '/bert_config.json'\n",
        "# bert_vocab_path =  bert_model + '/vocab.txt'\n",
        "# bert_checkpoint_path =  bert_model + '/bert_model.ckpt'\n",
        "# path_data = '/content/drive/MyDrive/Graduate/data/'\n",
        "# rel_dict_path = path_data+'rel2id.json'\n",
        "\n",
        "# train_path = path_data+ 'train.json'\n",
        "# dev_path = path_data+'dev.json'\n",
        "# test_path =path_data+'test.json'\n",
        "# now = datetime.now()\n",
        "# save_weights_path = '/content/drive/MyDrive/Graduate/model_{}/best_model.weights'.format(now.strftime(\"%d%m%Y\"))\n",
        "# LR = 1e-5\n",
        "# tokenizer = get_tokenizer(bert_vocab_path)\n",
        "# train_data, dev_data,test_data, rel2id, num_rels = load_data(train_path, dev_path,test_path, rel_dict_path)\n",
        "# subject_model, object_model, hbt_model = E2EModel( bert_config_path,bert_checkpoint_path,LR, num_rels)\n",
        "# id2rel = {value: key for key, value in rel2id.items()}\n",
        "\n",
        "# BATCH_SIZE = 2\n",
        "# EPOCH = 8\n",
        "# MAX_LEN = 100\n",
        "# STEPS = len(train_data) // BATCH_SIZE\n",
        "# data_manager = data_generator(train_data, tokenizer, rel2id, num_rels, MAX_LEN, BATCH_SIZE)\n",
        "# evaluator = Evaluate(subject_model, object_model, tokenizer, id2rel, dev_data, save_weights_path)\n",
        "# hbt_model.fit_generator(data_manager.__iter__(),\n",
        "#                               steps_per_epoch=STEPS,\n",
        "#                               epochs=EPOCH,\n",
        "#                               callbacks=[evaluator]\n",
        "#                               )\n",
        "# save_weights_path = '/content/drive/MyDrive/Graduate/model_{}/best.h5'.format(now.strftime(\"%d%m%Y\"))\n",
        "# hbt_model.save_weights(save_weights_path, overwrite=True, save_format='h5', options=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "FNxonfL-DrEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2haWrEtxvYm"
      },
      "outputs": [],
      "source": [
        "# import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TedtD66xXXt"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(hbt_model, show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict relation"
      ],
      "metadata": {
        "id": "YjJYPb1pDxz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = 'multi_cased_L-12_H-768_A-12'\n",
        "bert_config_path =  bert_model + '/bert_config.json'\n",
        "bert_vocab_path =  bert_model + '/vocab.txt'\n",
        "bert_checkpoint_path =  bert_model + '/bert_model.ckpt'\n",
        "path_data = '/content/drive/MyDrive/Graduate/data/'\n",
        "rel_dict_path = path_data+'rel2id.json'\n",
        "train_path = path_data+ 'train.json'\n",
        "dev_path = path_data+'dev.json'\n",
        "test_path =path_data+'test.json'\n",
        "LR = 1e-5\n",
        "\n",
        "tokenizer = get_tokenizer(bert_vocab_path)\n",
        "train_data, dev_data,test_data, rel2id, num_rels = load_data(train_path, dev_path,test_path, rel_dict_path)\n",
        "id2rel = {value: key for key, value in rel2id.items()}\n",
        "subject_model_test, object_model_test, hbt_model_test = E2EModel( bert_config_path,bert_checkpoint_path,LR, num_rels=7)\n",
        "hbt_model_test.load_weights('/content/drive/MyDrive/Graduate/model_17062023/best.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SMNR-sFwVag",
        "outputId": "bc3b6460-a5c5-40c4-aada-ffa6edc065ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data len: 3153\n",
            "test_data len: 421\n",
            "dev_data len: 631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.functional.Functional object at 0x7fb4bcbdaf20>\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 768)    177262848   ['input_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 768)          0           ['model_1[0][0]',                \n",
            "                                                                  'input_5[0][0]']                \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)              (None, 768)          0           ['model_1[0][0]',                \n",
            "                                                                  'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " average (Average)              (None, 768)          0           ['lambda_1[0][0]',               \n",
            "                                                                  'lambda_2[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, None, 768)    0           ['model_1[0][0]',                \n",
            "                                                                  'average[0][0]']                \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, None, 7)]    0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, None, 7)]    0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 1)      769         ['model_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 1)      769         ['model_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 7)      5383        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, None, 7)      5383        ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, None, 1)      0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, None, 1)      0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " tf.keras.backend.binary_crosse  (None, None, 7)     0           ['input_7[0][0]',                \n",
            " ntropy_2 (TFOpLambda)                                            'dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.keras.backend.binary_crosse  (None, None, 7)     0           ['input_8[0][0]',                \n",
            " ntropy_3 (TFOpLambda)                                            'dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " tf.keras.backend.binary_crosse  (None, None, 1)     0           ['tf.expand_dims[0][0]',         \n",
            " ntropy (TFOpLambda)                                              'dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, None, 1)      0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.keras.backend.binary_crosse  (None, None, 1)     0           ['tf.expand_dims_1[0][0]',       \n",
            " ntropy_1 (TFOpLambda)                                            'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_4 (TFOpLamb  (None, None, 1)     0           ['tf.keras.backend.binary_crossen\n",
            " da)                                                             tropy_2[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_7 (TFOpLamb  (None, None, 1)     0           ['tf.keras.backend.binary_crossen\n",
            " da)                                                             tropy_3[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, None, 1)      0           ['tf.keras.backend.binary_crossen\n",
            "                                                                 tropy[0][0]',                    \n",
            "                                                                  'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None, None, 1)     0           ['tf.keras.backend.binary_crossen\n",
            " )                                                               tropy_1[0][0]',                  \n",
            "                                                                  'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None, None, 1)     0           ['tf.math.reduce_sum_4[0][0]',   \n",
            " )                                                                'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None, None, 1)     0           ['tf.math.reduce_sum_7[0][0]',   \n",
            " )                                                                'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum (TFOpLambda  ()                  0           ['tf.math.multiply[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_1 (TFOpLamb  ()                  0           ['lambda[0][0]']                 \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_2 (TFOpLamb  ()                  0           ['tf.math.multiply_1[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_3 (TFOpLamb  ()                  0           ['lambda[0][0]']                 \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_5 (TFOpLamb  ()                  0           ['tf.math.multiply_2[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_6 (TFOpLamb  ()                  0           ['lambda[0][0]']                 \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_8 (TFOpLamb  ()                  0           ['tf.math.multiply_3[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.reduce_sum_9 (TFOpLamb  ()                  0           ['lambda[0][0]']                 \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   ()                   0           ['tf.math.reduce_sum[0][0]',     \n",
            "                                                                  'tf.math.reduce_sum_1[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.truediv_1 (TFOpLambda)  ()                  0           ['tf.math.reduce_sum_2[0][0]',   \n",
            "                                                                  'tf.math.reduce_sum_3[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.truediv_2 (TFOpLambda)  ()                  0           ['tf.math.reduce_sum_5[0][0]',   \n",
            "                                                                  'tf.math.reduce_sum_6[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.truediv_3 (TFOpLambda)  ()                  0           ['tf.math.reduce_sum_8[0][0]',   \n",
            "                                                                  'tf.math.reduce_sum_9[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.truediv[0][0]',        \n",
            " da)                                                              'tf.math.truediv_1[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.truediv_2[0][0]',      \n",
            " mbda)                                                            'tf.math.truediv_3[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.__operators__.add[0][0]',   \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)             ()                   0           ['tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 177,275,152\n",
            "Trainable params: 177,275,152\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV44IMrsmuxR"
      },
      "outputs": [],
      "source": [
        "# test_result_path = 'test_result.json'\n",
        "# precision, recall, f1_score = metric(subject_model_test, object_model_test, test_data, id2rel, tokenizer, True, test_result_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yJhnCVJ5HjA"
      },
      "outputs": [],
      "source": [
        "# print(precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3f_DQdm5Lvu"
      },
      "outputs": [],
      "source": [
        "# print(recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUEWf8us5Msw"
      },
      "outputs": [],
      "source": [
        "# print(f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rBt1uVkuEbo"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "def remove_punctuation(text):\n",
        "    # Create a translation table using the string.punctuation constant\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "\n",
        "    # Remove punctuation using the translation table\n",
        "    text_without_punct = text.translate(translator)\n",
        "    text_without_punct = \" \".join(text_without_punct.split())\n",
        "    return text_without_punct"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thefuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFHmxqyy0ect",
        "outputId": "4d3655f7-5304-46cf-83d8-a10693e8946e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thefuzz\n",
            "  Downloading thefuzz-0.19.0-py2.py3-none-any.whl (17 kB)\n",
            "Installing collected packages: thefuzz\n",
            "Successfully installed thefuzz-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_permutation_tuple(tuple1, tuple2):\n",
        "    # Sắp xếp các phần tử của tuple theo thứ tự tăng dần\n",
        "    sorted_tuple1 = tuple(sorted(tuple1))\n",
        "    sorted_tuple2 = tuple(sorted(tuple2))\n",
        "\n",
        "    # Kiểm tra xem các tuple đã được sắp xếp có giống nhau hay không\n",
        "    return sorted_tuple1 == sorted_tuple2"
      ],
      "metadata": {
        "id": "oMrhOchx8GtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from thefuzz import fuzz\n",
        "def remove_similiar_object(list_object):\n",
        "    list_remove = []\n",
        "    for idx in range(len(list_object)):\n",
        "            ratio = fuzz.ratio(list_object[idx][0], list_object[idx][2])\n",
        "            if ratio > 60:\n",
        "                list_remove.append(idx)\n",
        "\n",
        "    list_remove = list(set(list_remove))  # Loại bỏ các chỉ mục trùng lặp\n",
        "    list_remove.sort(reverse=True)\n",
        "\n",
        "    # Xóa các phần tử trong list dựa trên các chỉ mục đã cho\n",
        "    for index in list_remove:\n",
        "        if index >= 0 and index < len(list_object):\n",
        "            del list_object[index]\n",
        "    return list_object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2CvFNEXy6Ze",
        "outputId": "5f6157f9-67aa-4ae7-9930-8ebf3ae9980c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/thefuzz/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_permutation_tuples(lst):\n",
        "    new_lst = []\n",
        "    visited = set()\n",
        "\n",
        "    for i in range(len(lst)):\n",
        "        tuple1 = (lst[i][0],lst[i][2])\n",
        "        if i not in visited:\n",
        "            for j in range(i + 1, len(lst)):\n",
        "                tuple2 = (lst[j][0],lst[j][2])\n",
        "                if is_permutation_tuple(tuple1, tuple2):\n",
        "                    new_lst.append(lst[i])\n",
        "\n",
        "\n",
        "\n",
        "    return new_lst"
      ],
      "metadata": {
        "id": "UZ_Bac8l8j3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase_str(lst):\n",
        "    new_lst = []\n",
        "    for item in lst:\n",
        "      item = (item[0].lower(),item[1],item[2].lower())\n",
        "      new_lst.append(item)\n",
        "    return new_lst"
      ],
      "metadata": {
        "id": "hXQxi4whAwn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fqOPOi9S08E"
      },
      "outputs": [],
      "source": [
        "# # Model Extract\n",
        "# text = \"' Biển chết Trung Quốc ' hoá nửa hồng , nửa xanh Một hồ nước mặn được mệnh danh là ' biển Chết ' ở Trung Quốc đã hoá thành màu hồng ở một bên và thu hút lượng lớn du khách đến xem , NDTV đưa tin ngày 22-9 .\"\n",
        "# test = list(set(lowercase_str(extract_items(subject_model_test, object_model_test, tokenizer, remove_punctuation(text), id2rel))))\n",
        "# test = remove_permutation_tuples(remove_similiar_object(test))\n",
        "# print(test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_relation(sentence):\n",
        "   sentence = remove_punctuation(sentence)\n",
        "   predict_token = set(lowercase_str(extract_items(subject_model_test, object_model_test, tokenizer, sentence, id2rel)))\n",
        "   predict_relation = list(predict_token)\n",
        "   predict = remove_permutation_tuples(remove_similiar_object(predict_relation))\n",
        "   return predict"
      ],
      "metadata": {
        "id": "w7IL8xU1w7jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '/content/drive/MyDrive/Graduate/data/train_translated_squad.json'\n",
        "data_file = open(dataset, 'r', encoding='utf-8-sig')\n",
        "data = json.load(data_file)['data']"
      ],
      "metadata": {
        "id": "HUxRglfbDnwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs = []\n",
        "questions = []\n",
        "\n",
        "for row in data:\n",
        "    for paragraph in row['paragraphs']:\n",
        "        paragraphs.append(paragraph['context'])\n",
        "        for qa in paragraph['qas']:\n",
        "            questions.append((qa['question'], qa['answers'][0]['text']))"
      ],
      "metadata": {
        "id": "Zcml2Z7aEKHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from underthesea import sent_tokenize\n",
        "# from tqdm import tqdm\n",
        "# def segment_documents(docs, max_length=6, stride=3):\n",
        "#     \"\"\"\n",
        "#     Segment documents into smaller chunks\n",
        "#     \"\"\"\n",
        "#     print('Segmenting documents into smaller chunks...')\n",
        "#     segments = []\n",
        "#     for doc in tqdm(docs):\n",
        "#         sentences = sent_tokenize(doc)\n",
        "#         for i in range(0, len(sentences), stride):\n",
        "#             segment = ' '.join(sentences[i:i+max_length])\n",
        "#             segments.append([doc,segment])\n",
        "#     print('Number of documents:', len(docs))\n",
        "#     print('Number of segments:', len(segments))\n",
        "#     return segments\n",
        "#     corpus_split_df=segment_documents(paragraphs)"
      ],
      "metadata": {
        "id": "5CMWEgO7LYtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus_split_df=segment_documents(paragraphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HrfE2RPLbZ0",
        "outputId": "d19a44fb-b97f-4e21-9dac-d28a789d3a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmenting documents into smaller chunks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18925/18925 [00:02<00:00, 6991.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 18925\n",
            "Number of segments: 44815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.DataFrame(corpus_split_df,columns = ['docs','sentences'])"
      ],
      "metadata": {
        "id": "HQ2JilIQmwDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "UPheGcuPm50V",
        "outputId": "aa0e2188-4381-4298-ea5b-2dfa89067fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentences\n",
              "44805  Football và Cricket là môn thể thao phổ biến n...\n",
              "44806  Đây là sân vận động lớn nhất ở Nepal với công ...\n",
              "44807  Kathmandu là quê hương của các câu lạc bộ bóng...\n",
              "44808  Tổng chiều dài đường giao thông ở Nepal được g...\n",
              "44809  Các BP lộ, kết nối Kathmandu tới phần phía Đôn...\n",
              "44810  Sân bay quốc tế chính phục vụ Kathmandu và do ...\n",
              "44811  Hiện nay, khoảng 22 quốc tế kết nối Nepal tới ...\n",
              "44812  Trong khu vực, một số hãng hàng không Nepal ho...\n",
              "44813  Kathmandu Metropolitan City (KMC), nhằm thúc đ...\n",
              "44814  nỗ lực liên tục KMC là để tăng cường sự tương ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51b45157-bdcf-4178-8e1c-4ce957c8b258\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44805</th>\n",
              "      <td>Football và Cricket là môn thể thao phổ biến n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44806</th>\n",
              "      <td>Đây là sân vận động lớn nhất ở Nepal với công ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44807</th>\n",
              "      <td>Kathmandu là quê hương của các câu lạc bộ bóng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44808</th>\n",
              "      <td>Tổng chiều dài đường giao thông ở Nepal được g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44809</th>\n",
              "      <td>Các BP lộ, kết nối Kathmandu tới phần phía Đôn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44810</th>\n",
              "      <td>Sân bay quốc tế chính phục vụ Kathmandu và do ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44811</th>\n",
              "      <td>Hiện nay, khoảng 22 quốc tế kết nối Nepal tới ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44812</th>\n",
              "      <td>Trong khu vực, một số hãng hàng không Nepal ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44813</th>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44814</th>\n",
              "      <td>nỗ lực liên tục KMC là để tăng cường sự tương ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51b45157-bdcf-4178-8e1c-4ce957c8b258')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51b45157-bdcf-4178-8e1c-4ce957c8b258 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51b45157-bdcf-4178-8e1c-4ce957c8b258');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# num_parts = 10  # Số phần nhỏ hơn mong muốn\n",
        "# subset_size = len(df) // num_parts\n",
        "# subsets = [df.iloc[i:i+subset_size] for i in range(0, len(df), subset_size)]"
      ],
      "metadata": {
        "id": "sPgWbDPbq5cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subset=df.iloc[44810:44815]"
      ],
      "metadata": {
        "id": "n0zxGyI88foZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subset['relation']=subset['sentences'].progress_apply(lambda row: predict_relation(row))\n",
        "# with open('/content/drive/MyDrive/Graduate/data/subset10.json', 'w', encoding='utf-8') as f:\n",
        "#         subset.to_json(f,orient='records', force_ascii=False,indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yN7RYBi82rZ",
        "outputId": "0fbd7ef1-4e6b-43c4-d666-eaa762fb333a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "<ipython-input-57-56c20441b71b>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset['relation']=subset['sentences'].progress_apply(lambda row: predict_relation(row))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 0\n",
        "# for subset in subsets:\n",
        "#     file_path = '/content/drive/MyDrive/Graduate/data/subset{}.json'.format(i)\n",
        "#     if os.path.isfile(file_path):\n",
        "#       print(\"Batch :\",i)\n",
        "#       i = i + 1\n",
        "#       continue\n",
        "#     else:\n",
        "#       print(\"Batch :\",i)\n",
        "#       subset['relation']=subset['sentences'].progress_apply(lambda row: predict_relation(row))\n",
        "#       with open('/content/drive/MyDrive/Graduate/data/subset{}.json'.format(i), 'w', encoding='utf-8') as f:\n",
        "#         subset.to_json(f,orient='records', force_ascii=False,indent=4)\n",
        "#       i = i + 1"
      ],
      "metadata": {
        "id": "9A9Ji9u1u-Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_relation = pd.read_json(\"/content/drive/MyDrive/Graduate/data/subset0.json\", orient='records')\n",
        "# for i in range(1,11):\n",
        "#   concat_df = pd.read_json(\"/content/drive/MyDrive/Graduate/data/subset{}.json\".format(i), orient='records')\n",
        "#   df_relation=pd.concat([df_relation,concat_df])\n",
        "# df_relation.reset_index(drop=True,inplace = True)"
      ],
      "metadata": {
        "id": "X52JJOOH5Z0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df=df[df['sentences'] != '.'].reset_index(drop=True)\n",
        "# df_relation['docs']=df['docs']\n",
        "# new_df = df_relation.explode('relation').reset_index(drop=True)\n",
        "# new_order = ['docs', 'sentences', 'relation']\n",
        "# new_columns = new_df['relation'].apply(pd.Series)\n",
        "# new_columns.columns = ['subject', 'rel','object']\n",
        "# df = pd.concat([new_df, new_columns], axis=1)\n",
        "# df = df.drop('relation', axis=1)\n",
        "# with open('/content/drive/MyDrive/Graduate/data/data_query.json', 'w', encoding='utf-8') as f:\n",
        "#     df.to_json(f,orient='records', force_ascii=False,indent=4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kRyorbGNDZpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(\"/content/drive/MyDrive/Graduate/data/data_query.json\", orient='records')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "NwvS39OlDNia",
        "outputId": "a22e3eb2-2f4e-4ecc-c617-709fb23920ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     docs  \\\n",
              "0       Về mặt kiến ​​trúc, trường có một nhân vật Côn...   \n",
              "1       Về mặt kiến ​​trúc, trường có một nhân vật Côn...   \n",
              "2       Về mặt kiến ​​trúc, trường có một nhân vật Côn...   \n",
              "3       Về mặt kiến ​​trúc, trường có một nhân vật Côn...   \n",
              "4       Về mặt kiến ​​trúc, trường có một nhân vật Côn...   \n",
              "...                                                   ...   \n",
              "272910  Kathmandu Metropolitan City (KMC), nhằm thúc đ...   \n",
              "272911  Kathmandu Metropolitan City (KMC), nhằm thúc đ...   \n",
              "272912  Kathmandu Metropolitan City (KMC), nhằm thúc đ...   \n",
              "272913  Kathmandu Metropolitan City (KMC), nhằm thúc đ...   \n",
              "272914  Kathmandu Metropolitan City (KMC), nhằm thúc đ...   \n",
              "\n",
              "                                                sentences        subject  \\\n",
              "0       Về mặt kiến ​​trúc, trường có một nhân vật Côn...  tòa nhà chính   \n",
              "1       Về mặt kiến ​​trúc, trường có một nhân vật Côn...        lourdes   \n",
              "2       Về mặt kiến ​​trúc, trường có một nhân vật Côn...        lourdes   \n",
              "3       Về mặt kiến ​​trúc, trường có một nhân vật Côn...           pháp   \n",
              "4       Về mặt kiến ​​trúc, trường có một nhân vật Côn...           pháp   \n",
              "...                                                   ...            ...   \n",
              "272910  Kathmandu Metropolitan City (KMC), nhằm thúc đ...         yangon   \n",
              "272911  Kathmandu Metropolitan City (KMC), nhằm thúc đ...     trung quốc   \n",
              "272912  Kathmandu Metropolitan City (KMC), nhằm thúc đ...       nhật bản   \n",
              "272913  nỗ lực liên tục KMC là để tăng cường sự tương ...            kmc   \n",
              "272914  nỗ lực liên tục KMC là để tăng cường sự tương ...          saarc   \n",
              "\n",
              "            rel            object  \n",
              "0       LOC/LOC           lourdes  \n",
              "1       LOC/ORG         công giáo  \n",
              "2       LOC/LOC              pháp  \n",
              "3       LOC/LOC     tòa nhà chính  \n",
              "4       LOC/ORG         công giáo  \n",
              "...         ...               ...  \n",
              "272910  LOC/LOC           myanmar  \n",
              "272911  LOC/LOC           belarus  \n",
              "272912  LOC/LOC  tiểu bang oregon  \n",
              "272913  ORG/LOC         kathmandu  \n",
              "272914  ORG/LOC         kathmandu  \n",
              "\n",
              "[272915 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207d6f9c-6dc0-48b1-bc59-1298444c97be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docs</th>\n",
              "      <th>sentences</th>\n",
              "      <th>subject</th>\n",
              "      <th>rel</th>\n",
              "      <th>object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>tòa nhà chính</td>\n",
              "      <td>LOC/LOC</td>\n",
              "      <td>lourdes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>lourdes</td>\n",
              "      <td>LOC/ORG</td>\n",
              "      <td>công giáo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>lourdes</td>\n",
              "      <td>LOC/LOC</td>\n",
              "      <td>pháp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>pháp</td>\n",
              "      <td>LOC/LOC</td>\n",
              "      <td>tòa nhà chính</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>Về mặt kiến ​​trúc, trường có một nhân vật Côn...</td>\n",
              "      <td>pháp</td>\n",
              "      <td>LOC/ORG</td>\n",
              "      <td>công giáo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272910</th>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>yangon</td>\n",
              "      <td>LOC/LOC</td>\n",
              "      <td>myanmar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272911</th>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>trung quốc</td>\n",
              "      <td>LOC/LOC</td>\n",
              "      <td>belarus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272912</th>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>nhật bản</td>\n",
              "      <td>LOC/LOC</td>\n",
              "      <td>tiểu bang oregon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272913</th>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>nỗ lực liên tục KMC là để tăng cường sự tương ...</td>\n",
              "      <td>kmc</td>\n",
              "      <td>ORG/LOC</td>\n",
              "      <td>kathmandu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272914</th>\n",
              "      <td>Kathmandu Metropolitan City (KMC), nhằm thúc đ...</td>\n",
              "      <td>nỗ lực liên tục KMC là để tăng cường sự tương ...</td>\n",
              "      <td>saarc</td>\n",
              "      <td>ORG/LOC</td>\n",
              "      <td>kathmandu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>272915 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207d6f9c-6dc0-48b1-bc59-1298444c97be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207d6f9c-6dc0-48b1-bc59-1298444c97be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207d6f9c-6dc0-48b1-bc59-1298444c97be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"nguyenvulebinh/vi-mrc-large\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"nguyenvulebinh/vi-mrc-large\")\n",
        "\n",
        "# device gpu\n",
        "qa_model = pipeline(\"question-answering\", model=model,tokenizer=tokenizer, device=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b827bb1467fd485881b3cbbb64a262fb",
            "68f578fa391e4b98af0e4065bc633c5d",
            "2e73e3ebc1f54a7db4bdab7018a35131",
            "33380c434f444151b9ad9823dce30b0d",
            "381a74f9bcb2450b9ced58edc8d28b65",
            "b102a2da807e4e7eba6661fa2b5ad8d8",
            "5bf6743386604003b78fc7a8fb8cf64b",
            "c015dad27785465c88b835c0a22f2c2d",
            "a2746c3be23448978900db0d8e63ec26",
            "9ecc066fbfb9450b8c50ea4ed6ca316c",
            "7d4865f959f94475b8851d89943e9298",
            "34114dac4a4242069d05b7fe31229706",
            "9173bf23fb3e471895318b39c45bb68a",
            "3e6f1efcd665451592bb2418feb1c0e0",
            "5861b523f78043249795217848f4e473",
            "1dcd9f188e104079adff1ca4d05168ae",
            "7cbf908a46434c6c8b546d36ce8e99aa",
            "271c43aba9f24a45b8acdf1ef40f4179",
            "7dcc86a04575468283f75b6d11d597a4",
            "92e6931c905144f48dae2e527ab377a1",
            "729d66c192244310a47413950e13c53e",
            "86e3aea2d76849a0a7dbb14da9b33b32",
            "029d5d85c1e54c21ac66ebcdac4c8fec",
            "19b0a0aa7e5742c48afc0b3d78cadb3d",
            "dc4fcfc465f74df2909c2a90baeffa78",
            "ba0d1cbb69ba4fd2a414c545d53e966f",
            "72fa5e22dadd47b094156fa724412ed6",
            "58827e795cf04c80961d87dcade45087",
            "0d12638a4e3c4896ad4de647258a59a9",
            "52d734e0f02d42bc963ea82ae0bc18e6",
            "6b8ecfe6d2c24e6fa7c221c92e9902be",
            "6f67cd5cfcfc40a5a3170704b0a88c09",
            "93a2dacc8da64064b5de967a7c3c9c5e",
            "9528a7cdf80f44c3a0a2a935a0782b55",
            "cf2eb52139904e229267ba67e096723b",
            "cdb8e6d6b40745d091de92bdb3adbc2f",
            "1852b46573614a02ab53d9ceae9134d8",
            "d92a44e8ecba438bbc9bc8c87acf9552",
            "668c66b990a24cdd8e74bec91526691e",
            "2d743e01c9994db3b7910430f47c9f75",
            "9051a48119144dc7bc8d53304ee8d2ad",
            "996991d9fd474d2aa02547ba2502b532",
            "17b389f924984e81b30d403e40fb322c",
            "b47c29626b3c4f36ae290a5eac40f083"
          ]
        },
        "id": "7l64O0DfEM1l",
        "outputId": "9883d16c-51db-42a4-d288-e10ca7992e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b827bb1467fd485881b3cbbb64a262fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34114dac4a4242069d05b7fe31229706"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "029d5d85c1e54c21ac66ebcdac4c8fec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9528a7cdf80f44c3a0a2a935a0782b55"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from underthesea import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "def segment_documents(docs, max_length=6, stride=3):\n",
        "    \"\"\"\n",
        "    Segment documents into smaller chunks\n",
        "    \"\"\"\n",
        "    print('Segmenting documents into smaller chunks...')\n",
        "    segments = []\n",
        "    for doc in tqdm(docs):\n",
        "        sentences = sent_tokenize(doc)\n",
        "        for i in range(0, len(sentences), stride):\n",
        "            segment = ' '.join(sentences[i:i+max_length])\n",
        "            segments.append(segment)\n",
        "    print('Number of documents:', len(docs))\n",
        "    print('Number of segments:', len(segments))\n",
        "    return segments\n",
        "corpus_split_df=segment_documents(paragraphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y8HktcpDtSy",
        "outputId": "72b977a2-b736-4e87-c162-983a3dc9a16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmenting documents into smaller chunks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18925/18925 [00:04<00:00, 4495.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 18925\n",
            "Number of segments: 44815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "LOAD = False\n",
        "\n",
        "if LOAD:\n",
        "    vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
        "else:\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus_split_df)\n",
        "    pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "6Ds-Jiu6EjFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_exact_match(prediction, truth):\n",
        "    return int(prediction == truth)\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = prediction.split()\n",
        "    truth_tokens = truth.split()\n",
        "\n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "\n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "\n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "\n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "\n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ],
      "metadata": {
        "id": "8f-b0-JjE0pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ltkk/vietnamese-stopwords/master/stopwords.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltgYqulyEbfG",
        "outputId": "f04665dc-9725-4e5f-b17a-46594cdbebb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-22 21:52:47--  https://raw.githubusercontent.com/ltkk/vietnamese-stopwords/master/stopwords.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 392 [text/plain]\n",
            "Saving to: ‘stopwords.txt’\n",
            "\n",
            "stopwords.txt       100%[===================>]     392  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-22 21:52:47 (20.0 MB/s) - ‘stopwords.txt’ saved [392/392]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKstLgrbEi6C",
        "outputId": "dfc4bc7e-ebc6-4eb4-f7aa-57633f6d63db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from yake) (0.8.10)\n",
            "Requirement already satisfied: click>=6.0 in /usr/local/lib/python3.10/dist-packages (from yake) (8.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from yake) (1.22.4)\n",
            "Requirement already satisfied: segtok in /usr/local/lib/python3.10/dist-packages (from yake) (1.5.11)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from yake) (3.1)\n",
            "Collecting jellyfish (from yake)\n",
            "  Downloading jellyfish-0.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from segtok->yake) (2022.10.31)\n",
            "Installing collected packages: jellyfish, yake\n",
            "Successfully installed jellyfish-0.11.2 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCt3gqeTGMaY",
        "outputId": "ce61f02c-ca52-4204-e804-22ee37e41846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Vương Cung Thánh Đường của trái tim Thánh tại Notre Dame là bên cạnh để mà cấu trúc?',\n",
              " 'Tòa nhà Chính')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "text = questions[2][0]\n",
        "\n",
        "stopwords = open('stopwords.txt').read().splitlines()\n",
        "\n",
        "# Khởi tạo YAKE với ngôn ngữ tiếng Việt (làm màu), sinh ứng viên 1-gram và 2-gram, với custom stopwrod\n",
        "kw_extractor = yake.KeywordExtractor(lan='vi', n=2, stopwords=stopwords)\n",
        "\n",
        "# Truy vấn trích rút từ khóa\n",
        "keywords = kw_extractor.extract_keywords(text)\n",
        "\n"
      ],
      "metadata": {
        "id": "zuz4ghS9D629"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df[(df['subject']==keywords[0][0].lower()) | (df['object']==keywords[0][0].lower())]['sentences'].drop_duplicates().tolist():\n",
        "   print(\"true\")\n",
        "else:\n",
        "   print(\"false\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhsue5uBHIyH",
        "outputId": "89d43273-f44a-4eb0-fdc0-6390cb1b582e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions_ = questions[:100]"
      ],
      "metadata": {
        "id": "qBvzGyj_OOa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With add-on"
      ],
      "metadata": {
        "id": "HPYhB9y2Ox6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score = w0 \\* retrieval_score + w1 \\* predict_score (linear regression)\n",
        "import yake\n",
        "\n",
        "results = []\n",
        "for q in tqdm(questions_):\n",
        "  test_question = q[0]\n",
        "  #Tokenize question in test data\n",
        "  # stopwords = open('stopwords.txt').read().splitlines()\n",
        "\n",
        "  kw_extractor = yake.KeywordExtractor(lan='vi', n=1)\n",
        "\n",
        "# Truy vấn trích rút từ khóa\n",
        "  keywords = kw_extractor.extract_keywords(test_question)\n",
        "  search_values = keywords[0][0].lower()\n",
        "  X_new = df[(df['subject']==search_values) | (df['object']==search_values)]['sentences'].drop_duplicates().tolist()\n",
        "  if X_new:\n",
        "    query_vector=vectorizer.transform([test_question])\n",
        "    X_new = vectorizer.transform(X_new)\n",
        "    sim_maxtrix = sklearn.metrics.pairwise.cosine_similarity(query_vector, X_new )\n",
        "    sim_maxtrix = np.reshape(sim_maxtrix, (-1,))\n",
        "  else:\n",
        "    query_vector=vectorizer.transform([test_question])\n",
        "    sim_maxtrix = sklearn.metrics.pairwise.cosine_similarity(query_vector, X )\n",
        "    sim_maxtrix = np.reshape(sim_maxtrix, (-1,))\n",
        "  # top 10\n",
        "  idx = (-sim_maxtrix).argsort()[:10]\n",
        "  temp_result = []\n",
        "  for i in idx:\n",
        "    retrieval_score = sim_maxtrix[i]\n",
        "    result = qa_model({'question': test_question, 'context': corpus_split_df[i]})\n",
        "    # rename result['score'] to predict_score\n",
        "    result['retrieval_score'] = retrieval_score\n",
        "    result['predict_score'] = result['score']\n",
        "    result['context'] = corpus_split_df[i]\n",
        "    del result['score']\n",
        "    temp_result.append(result)\n",
        "  results.append({\n",
        "      'question': test_question,\n",
        "      'answers': temp_result,\n",
        "      'true_answer': q[1]\n",
        "  })"
      ],
      "metadata": {
        "id": "HUH9UEpcE6_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da14012-a51b-4285-ea94-377118134b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:59<00:00,  1.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05OfJ84vPKN_",
        "outputId": "fbce4cbc-a23d-425b-c8cd-43f377af7fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find best w0, w1\n",
        "def compute_score(w0, w1, results):\n",
        "    exact_match = 0\n",
        "    f1 = 0\n",
        "    for test in results:\n",
        "        test_answers= test['answers']\n",
        "        for answer in test_answers:\n",
        "            answer['score'] = w0 * answer['retrieval_score'] + w1 * answer['predict_score']\n",
        "        test_answers = sorted(test_answers, key=lambda x: x['score'], reverse=True)\n",
        "        best_answer = test_answers[0]\n",
        "        exact_match += compute_exact_match(best_answer['answer'], test['true_answer'])\n",
        "        f1 += compute_f1(best_answer['answer'], test['true_answer'])\n",
        "    f1 = f1 / len(results)\n",
        "    return exact_match, f1\n",
        "\n",
        "exact_match, f1 = compute_score(0.5, 0.5, results)\n",
        "print('with add-on')\n",
        "\n",
        "print('exact_match:', exact_match)\n",
        "print('f1:', f1)\n",
        "\n",
        "# find best w0, w1\n",
        "best_w0 = 0\n",
        "best_w1 = 0\n",
        "best_exact_match = 0\n",
        "best_f1 = 0\n",
        "for w0 in np.arange(0, 1, 0.001):\n",
        "    for w1 in np.arange(0, 1, 0.001):\n",
        "        if w0 + w1 == 1:\n",
        "            exact_match, f1 = compute_score(w0, w1, results)\n",
        "            if exact_match > best_exact_match:\n",
        "                best_w0 = w0\n",
        "                best_w1 = w1\n",
        "                best_exact_match = exact_match\n",
        "                best_f1 = f1\n",
        "print()\n",
        "print('best_w0:', best_w0)\n",
        "print('best_w1:', best_w1)\n",
        "print('best_exact_match:', best_exact_match)\n",
        "print('best_f1:', best_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_1UKcf7PalZ",
        "outputId": "d3814bec-0d21-4c5b-b7f7-81dbc9be4221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with add-on\n",
            "exact_match: 18\n",
            "f1: 0.25140151515151515\n",
            "\n",
            "best_w0: 0.321\n",
            "best_w1: 0.679\n",
            "best_exact_match: 18\n",
            "best_f1: 0.25140151515151515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# without add-on"
      ],
      "metadata": {
        "id": "HJU_n4TIPAn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# score = w0 \\* retrieval_score + w1 \\* predict_score (linear regression)\n",
        "import yake\n",
        "\n",
        "results = []\n",
        "for q in tqdm(questions_):\n",
        "  test_question = q[0]\n",
        "  #Tokenize question in test data\n",
        "  query_vector=vectorizer.transform([test_question])\n",
        "  sim_maxtrix = sklearn.metrics.pairwise.cosine_similarity(query_vector, X )\n",
        "  sim_maxtrix = np.reshape(sim_maxtrix, (-1,))\n",
        "  # top 10\n",
        "  idx = (-sim_maxtrix).argsort()[:10]\n",
        "  temp_result = []\n",
        "  for i in idx:\n",
        "    retrieval_score = sim_maxtrix[i]\n",
        "    result = qa_model({'question': test_question, 'context': corpus_split_df[i]})\n",
        "    # rename result['score'] to predict_score\n",
        "    result['retrieval_score'] = retrieval_score\n",
        "    result['predict_score'] = result['score']\n",
        "    result['context'] = corpus_split_df[i]\n",
        "    del result['score']\n",
        "    temp_result.append(result)\n",
        "  results.append({\n",
        "      'question': test_question,\n",
        "      'answers': temp_result,\n",
        "      'true_answer': q[1]\n",
        "  })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecL8fvCoO-tN",
        "outputId": "f4bbc953-20e6-4944-8090-0c7cd5208555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:55<00:00,  1.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find best w0, w1\n",
        "def compute_score(w0, w1, results):\n",
        "    exact_match = 0\n",
        "    f1 = 0\n",
        "    for test in results:\n",
        "        test_answers= test['answers']\n",
        "        for answer in test_answers:\n",
        "            answer['score'] = w0 * answer['retrieval_score'] + w1 * answer['predict_score']\n",
        "        test_answers = sorted(test_answers, key=lambda x: x['score'], reverse=True)\n",
        "        best_answer = test_answers[0]\n",
        "        exact_match += compute_exact_match(best_answer['answer'], test['true_answer'])\n",
        "        f1 += compute_f1(best_answer['answer'], test['true_answer'])\n",
        "    f1 = f1 / len(results)\n",
        "    return exact_match, f1\n",
        "\n",
        "exact_match, f1 = compute_score(0.5, 0.5, results)\n",
        "print('without add-on')\n",
        "print('exact_match:', exact_match)\n",
        "print('f1:', f1)\n",
        "\n",
        "# find best w0, w1\n",
        "best_w0 = 0\n",
        "best_w1 = 0\n",
        "best_exact_match = 0\n",
        "best_f1 = 0\n",
        "for w0 in np.arange(0, 1, 0.001):\n",
        "    for w1 in np.arange(0, 1, 0.001):\n",
        "        if w0 + w1 == 1:\n",
        "            exact_match, f1 = compute_score(w0, w1, results)\n",
        "            if exact_match > best_exact_match:\n",
        "                best_w0 = w0\n",
        "                best_w1 = w1\n",
        "                best_exact_match = exact_match\n",
        "                best_f1 = f1\n",
        "print()\n",
        "print('best_w0:', best_w0)\n",
        "print('best_w1:', best_w1)\n",
        "print('best_exact_match:', best_exact_match)\n",
        "print('best_f1:', best_f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJOlejj0Phkr",
        "outputId": "266f5257-2fff-4400-c59e-f1384cf5350f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "without add-on\n",
            "exact_match: 17\n",
            "f1: 0.24348484848484847\n",
            "\n",
            "best_w0: 0.321\n",
            "best_w1: 0.679\n",
            "best_exact_match: 17\n",
            "best_f1: 0.24348484848484847\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b827bb1467fd485881b3cbbb64a262fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68f578fa391e4b98af0e4065bc633c5d",
              "IPY_MODEL_2e73e3ebc1f54a7db4bdab7018a35131",
              "IPY_MODEL_33380c434f444151b9ad9823dce30b0d"
            ],
            "layout": "IPY_MODEL_381a74f9bcb2450b9ced58edc8d28b65"
          }
        },
        "68f578fa391e4b98af0e4065bc633c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b102a2da807e4e7eba6661fa2b5ad8d8",
            "placeholder": "​",
            "style": "IPY_MODEL_5bf6743386604003b78fc7a8fb8cf64b",
            "value": "Downloading (…)/main/tokenizer.json: "
          }
        },
        "2e73e3ebc1f54a7db4bdab7018a35131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c015dad27785465c88b835c0a22f2c2d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2746c3be23448978900db0d8e63ec26",
            "value": 1
          }
        },
        "33380c434f444151b9ad9823dce30b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ecc066fbfb9450b8c50ea4ed6ca316c",
            "placeholder": "​",
            "style": "IPY_MODEL_7d4865f959f94475b8851d89943e9298",
            "value": " 9.08M/? [00:01&lt;00:00, 7.11MB/s]"
          }
        },
        "381a74f9bcb2450b9ced58edc8d28b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b102a2da807e4e7eba6661fa2b5ad8d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf6743386604003b78fc7a8fb8cf64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c015dad27785465c88b835c0a22f2c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a2746c3be23448978900db0d8e63ec26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ecc066fbfb9450b8c50ea4ed6ca316c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4865f959f94475b8851d89943e9298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34114dac4a4242069d05b7fe31229706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9173bf23fb3e471895318b39c45bb68a",
              "IPY_MODEL_3e6f1efcd665451592bb2418feb1c0e0",
              "IPY_MODEL_5861b523f78043249795217848f4e473"
            ],
            "layout": "IPY_MODEL_1dcd9f188e104079adff1ca4d05168ae"
          }
        },
        "9173bf23fb3e471895318b39c45bb68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cbf908a46434c6c8b546d36ce8e99aa",
            "placeholder": "​",
            "style": "IPY_MODEL_271c43aba9f24a45b8acdf1ef40f4179",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "3e6f1efcd665451592bb2418feb1c0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dcc86a04575468283f75b6d11d597a4",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92e6931c905144f48dae2e527ab377a1",
            "value": 239
          }
        },
        "5861b523f78043249795217848f4e473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729d66c192244310a47413950e13c53e",
            "placeholder": "​",
            "style": "IPY_MODEL_86e3aea2d76849a0a7dbb14da9b33b32",
            "value": " 239/239 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "1dcd9f188e104079adff1ca4d05168ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbf908a46434c6c8b546d36ce8e99aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271c43aba9f24a45b8acdf1ef40f4179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dcc86a04575468283f75b6d11d597a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e6931c905144f48dae2e527ab377a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "729d66c192244310a47413950e13c53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e3aea2d76849a0a7dbb14da9b33b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "029d5d85c1e54c21ac66ebcdac4c8fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19b0a0aa7e5742c48afc0b3d78cadb3d",
              "IPY_MODEL_dc4fcfc465f74df2909c2a90baeffa78",
              "IPY_MODEL_ba0d1cbb69ba4fd2a414c545d53e966f"
            ],
            "layout": "IPY_MODEL_72fa5e22dadd47b094156fa724412ed6"
          }
        },
        "19b0a0aa7e5742c48afc0b3d78cadb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58827e795cf04c80961d87dcade45087",
            "placeholder": "​",
            "style": "IPY_MODEL_0d12638a4e3c4896ad4de647258a59a9",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "dc4fcfc465f74df2909c2a90baeffa78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d734e0f02d42bc963ea82ae0bc18e6",
            "max": 690,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b8ecfe6d2c24e6fa7c221c92e9902be",
            "value": 690
          }
        },
        "ba0d1cbb69ba4fd2a414c545d53e966f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f67cd5cfcfc40a5a3170704b0a88c09",
            "placeholder": "​",
            "style": "IPY_MODEL_93a2dacc8da64064b5de967a7c3c9c5e",
            "value": " 690/690 [00:00&lt;00:00, 47.9kB/s]"
          }
        },
        "72fa5e22dadd47b094156fa724412ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58827e795cf04c80961d87dcade45087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d12638a4e3c4896ad4de647258a59a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52d734e0f02d42bc963ea82ae0bc18e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8ecfe6d2c24e6fa7c221c92e9902be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f67cd5cfcfc40a5a3170704b0a88c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a2dacc8da64064b5de967a7c3c9c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9528a7cdf80f44c3a0a2a935a0782b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf2eb52139904e229267ba67e096723b",
              "IPY_MODEL_cdb8e6d6b40745d091de92bdb3adbc2f",
              "IPY_MODEL_1852b46573614a02ab53d9ceae9134d8"
            ],
            "layout": "IPY_MODEL_d92a44e8ecba438bbc9bc8c87acf9552"
          }
        },
        "cf2eb52139904e229267ba67e096723b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_668c66b990a24cdd8e74bec91526691e",
            "placeholder": "​",
            "style": "IPY_MODEL_2d743e01c9994db3b7910430f47c9f75",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "cdb8e6d6b40745d091de92bdb3adbc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9051a48119144dc7bc8d53304ee8d2ad",
            "max": 2235534897,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_996991d9fd474d2aa02547ba2502b532",
            "value": 2235534897
          }
        },
        "1852b46573614a02ab53d9ceae9134d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17b389f924984e81b30d403e40fb322c",
            "placeholder": "​",
            "style": "IPY_MODEL_b47c29626b3c4f36ae290a5eac40f083",
            "value": " 2.24G/2.24G [00:16&lt;00:00, 178MB/s]"
          }
        },
        "d92a44e8ecba438bbc9bc8c87acf9552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668c66b990a24cdd8e74bec91526691e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d743e01c9994db3b7910430f47c9f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9051a48119144dc7bc8d53304ee8d2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996991d9fd474d2aa02547ba2502b532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17b389f924984e81b30d403e40fb322c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47c29626b3c4f36ae290a5eac40f083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}